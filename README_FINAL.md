# KDSH 2.0 Track-A: Narrative Consistency Verification System - Final Model

A sophisticated system for verifying the consistency of character backstories against full novel narratives using multi-stage decision logic, semantic embeddings, and LLM-based reasoning.

## ğŸ¯ Project Overview

**Goal**: Determine whether hypothetical character backstories are causally and logically consistent with full narratives of long-form novels (100k+ words).

**Approach**: Multi-stage verification system with 3-perspective ensemble, character-specific retrieval, and high-stakes calibration.

## ğŸ—ï¸ System Architecture

### Core Pipeline
```
Raw Books â†’ C-D-F-G Chunking â†’ E5-Large-v2 Embeddings â†’ FAISS Indexing â†’ 
Character/Temporal Boosted Retrieval (15 chunks) â†’ Atomic Decomposition (5 atoms) â†’ 
3-Perspective Ensemble (strict/moderate/lenient) â†’ High-Stakes Calibration â†’ 
Threshold Tuning (2/3 votes) â†’ Final Decision
```

### Key Components

- **ğŸ“š Advanced Chunking**: C-D-F-G strategy with sliding windows and character tagging
- **ğŸ” Boosted Retrieval**: Character-specific (2x) and temporal filtering (1.5x)
- **ğŸ§  Plot-Critical Atoms**: 5 verifiable facts (names, dates, events, locations, causes)
- **âš–ï¸ 3-Perspective Ensemble**: Strict/moderate/lenient with 2/3 voting threshold
- **ğŸ¯ High-Stakes Calibration**: Unsupported plot-critical events â†’ HARD_VIOLATION
- **ğŸ“Š Comprehensive Metrics**: Accuracy, Precision, Recall, F1-Score, Confusion Matrix

## ğŸš€ Quick Start (Reproducible)

### Prerequisites
```bash
pip install -r requirements.txt
```

**Required packages**:
- `mistralai==1.2.4`
- `sentence-transformers==3.3.1`
- `faiss-cpu==1.9.0` (or `faiss-gpu`)
- `torch==2.5.1`
- `python-dotenv==1.0.1`
- `numpy==2.2.0`
- `pandas==2.2.3`

### Step 1: Setup API Key

Create `.env` file:
```bash
MISTRAL_API_KEY=your_actual_api_key
```

Get key at: https://console.mistral.ai/

### Step 2: Build Cache (One-time, ~10-15 min)

```bash
python build_cache.py
```

Generates:
- `cache/chunks/` - Book chunks
- `cache/embeddings/` - FAISS indices

### Step 3: Run Training Evaluation (~20-30 min)

```bash
python test_full_clean.py
```

Expected output:
```
=== Dual Agent System: 15 Chunks (1-3-6 batches) ===
Loaded 80 total claims
...
=== RESULTS ===
Correct: 54/80
Accuracy: 67.50%
Precision: 65.00%
Recall: 52.00%
F1-Score: 57.78%
```

### Step 4: Generate Test Predictions (~15-20 min)

```bash
python run_test.py
```

Output: `results.csv` with format:
```csv
story_id,prediction,rationale
test_001,0,"Found 2 violations..."
test_002,1,"Found 3 supported atoms..."
```

## ğŸ“Š Performance Results

### Final Metrics (80 Training Claims)
- **Accuracy**: 67.50%
- **Precision**: 65.00%
- **Recall**: 52.00%
- **F1-Score**: 57.78%

### API Usage
- **Per Claim**: ~30-45 calls (1 decomposition + 3 perspectives Ã— 5 atoms Ã— 3 batches)
- **80 Claims**: ~2,400-3,600 calls
- **Time**: ~20-30 minutes
- **Cost**: ~$1-2 (Mistral Small 2503)

## ğŸ”§ Key Optimizations

1. **Character-Specific Retrieval Boost (2x)**: +1-2% accuracy
2. **Temporal Filtering (1.5x)**: +1-2% accuracy
3. **Contradiction Threshold Tuning (2/3 votes)**: +1-3% accuracy
4. **High-Stakes Calibration**: +1-2% accuracy
5. **Plot-Critical Atoms (5 focused facts)**: +3-5% accuracy

**Total Expected Improvement**: +7-14% over baseline

## ğŸ› ï¸ Configuration

### Model Settings
- **Embeddings**: `intfloat/e5-large-v2` (local, GPU/CPU)
- **LLM**: `mistral-small-2503` (API)
- **Chunks**: 15 retrieved, ~850 tokens each
- **Atoms**: 5 plot-critical facts
- **Ensemble**: 3 perspectives (strict/moderate/lenient)
- **Timeout**: 30s per API call

### Environment Variables
```bash
MISTRAL_API_KEY=your_key_here
```

## ğŸ“ Project Structure

```
kdsh-2.0/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ semantic_index.py         # Retrieval with character/temporal boost
â”‚   â”œâ”€â”€ final_decision_ensemble.py # 3-perspective ensemble
â”‚   â”œâ”€â”€ claim_decomposer.py       # Plot-critical atom extraction
â”‚   â”œâ”€â”€ grounded_inference.py     # Mistral API integration
â”‚   â”œâ”€â”€ claim_classifier.py
â”‚   â”œâ”€â”€ bounded_retrieval.py
â”‚   â”œâ”€â”€ chunking.py
â”‚   â”œâ”€â”€ load_books.py
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ raw/books/
â”œâ”€â”€ cache/
â”‚   â”œâ”€â”€ chunks/
â”‚   â””â”€â”€ embeddings/
â”œâ”€â”€ build_cache.py
â”œâ”€â”€ test_full_clean.py
â”œâ”€â”€ run_test.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”„ Reproducibility Checklist

- âœ… Install exact package versions from `requirements.txt`
- âœ… Set `MISTRAL_API_KEY` in `.env` file
- âœ… Run `build_cache.py` to generate embeddings
- âœ… Run `test_full_clean.py` for training evaluation
- âœ… Run `run_test.py` for test predictions
- âœ… Results saved to `results.csv`

## ğŸ“„ License

Kharagpur Data Science Hackathon 2026

---

**Status**: Final Production Model âœ…  
**Branch**: `final_model`  
**Accuracy**: 67.50% (target: 75%+)  
**Last Updated**: 2025
